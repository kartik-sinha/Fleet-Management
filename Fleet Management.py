# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Dc7-6casPt9WRvp9kTTgAf3HMyE_c2p
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from scipy.optimize import linear_sum_assignment
import os # Added to handle file paths

# ---
# CONFIGURATION CONSTANTS
# ---
# Define costs for our optimization model
FUEL_PRICE_PER_LITER = 1.5  # $ per liter
CO2_PRICE_PER_KG = 0.1      # $ per kg (carbon tax/cost)
DRIVER_WAGE_PER_HOUR = 25   # $ per hour
AVG_SPEED_KMH = 45          # Average speed for calculating time

# ---
# 1. DATA LOADING
# ---
def load_data(vehicle_path, routes_path):
    """
    Loads the real CSV files from the specified paths.
    """
    print(f"Loading data from: \n {vehicle_path} \n {routes_path}")

    # Handle potential file path issues
    if not os.path.exists(vehicle_path):
        print(f"Error: File not found at {vehicle_path}")
        return None, None
    if not os.path.exists(routes_path):
        print(f"Error: File not found at {routes_path}")
        return None, None

    try:
        # Load the CSVs
        vehicle_fleet_df = pd.read_csv(vehicle_path)
        routes_distance_df = pd.read_csv(routes_path)

        # Fixing a potential typo in the column name (remove leading/trailing spaces)
        routes_distance_df.columns = routes_distance_df.columns.str.strip()
        vehicle_fleet_df.columns = vehicle_fleet_df.columns.str.strip()

        # Check for user's typo "Traffic _Delay_Minutes"
        if 'Traffic _Delay_Minutes' in routes_distance_df.columns:
            routes_distance_df.rename(
                columns={'Traffic _Delay_Minutes': 'Traffic_Delay_Minutes'},
                inplace=True
            )

        print("Data loaded successfully.")
        return vehicle_fleet_df, routes_distance_df

    except Exception as e:
        print(f"An error occurred while loading data: {e}")
        return None, None

# ---
# 2. DATA VISUALIZATION
# ---
def visualize_data(vehicles, routes):
    """
    Generates and displays plots for Exploratory Data Analysis (EDA).
    Uses the new column names.
    """
    print("\n--- ðŸ“Š Starting Visualization ---")

    # Set up the figure
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('EDA: Fleet and Route Analysis', fontsize=20, y=1.02)

    # Plot 1: Fleet Capacity Distribution
    sns.histplot(vehicles['Capacity_KG'], kde=True, ax=axes[0, 0])
    axes[0, 0].set_title('Fleet: Vehicle Capacity Distribution')
    axes[0, 0].set_xlabel('Capacity (kg)')

    # Plot 2: Fleet Status
    sns.countplot(data=vehicles, x='Status', ax=axes[0, 1], palette='pastel')
    axes[0, 1].set_title('Fleet: Current Vehicle Status')

    # Plot 3: Route Distance Distribution
    sns.histplot(routes['Distance_KM'], kde=True, ax=axes[1, 0], color='green')
    axes[1, 0].set_title('Routes: Order Distance Distribution')
    axes[1, 0].set_xlabel('Distance (km)')

    # Plot 4: Route Distance vs. Fuel Consumption
    sns.scatterplot(data=routes, x='Distance_KM', y='Fuel_Consumption_L', ax=axes[1, 1], alpha=0.6, color='red')
    axes[1, 1].set_title('Routes: Distance vs. Fuel (Historical)')

    plt.tight_layout()
    plt.show()

    print("--- ðŸ“Š Visualization Complete ---")

# ---
# 3. REGRESSION MODEL (Predicting Costs)
# ---
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split # <-- Import this

# ---
# 3. REGRESSION MODEL (Predicting Costs)
# ---
def train_cost_model(routes_df):
    """
    Trains and EVALUATES a regression model to predict fuel consumption.
    """
    print("\n--- ðŸ¤– Training and Evaluating Regression Model ---")

    features = ['Distance_KM', 'Weather_Impact']
    target = 'Fuel_Consumption_L'

    X = routes_df[features]
    y = routes_df[target]

    # --- NEW: Split data into train and test sets ---
    # This lets us evaluate how well the model performs on "unseen" data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # --- Define pre-processing pipeline ---
    categorical_features = ['Weather_Impact']
    numeric_features = ['Distance_KM']

    preprocessor = ColumnTransformer(
        transformers=[
            ('num', 'passthrough', numeric_features),
            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
        ])

    # --- Create the full model pipeline ---
    model_pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))
    ])

    # --- Train the model on the training data ---
    model_pipeline.fit(X_train, y_train)

    print("Model trained successfully.")

    print("\n--- Model Evaluation (on Test Data) ---")
    y_pred = model_pipeline.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    print(f"  R-squared (RÂ²): {r2:.3f}")
    print(f"  Mean Squared Error (MAE): {rmse:.2f} liters")
    print(f"  Root Mean Squared Error (RMSE): {mse:.2f} liters")
    print("------------------------------------------")


    print("Re-training model on all data for final use...")
    model_pipeline.fit(X, y)

    return model_pipeline

def create_new_orders():
    """
    Simulates a batch of new orders that need to be assigned.
    Uses the new column structure.
    """
    print("\n--- ðŸšš Simulating 5 new incoming orders ---")
    new_orders_data = {
        'Order_ID': ['ORD-001', 'ORD-002', 'ORD-003', 'ORD-004', 'ORD-005'],
        'Capacity_KG': [800, 2200, 5000, 1200, 400], # Renamed
        'Distance_KM': [50, 120, 80, 250, 30],      # Renamed
        'Start_Location': ["10,20", "50,40", "80,75", "25,30", "90,85"], # "X,Y" format
        'Weather_Impact': ['None', 'Low', 'None', 'Medium', 'None']
    }
    return pd.DataFrame(new_orders_data)

def parse_location(location_str):
    """Helper function to parse "X,Y" string into two floats."""
    try:
        parts = location_str.split(',')
        return float(parts[0]), float(parts[1])
    except Exception as e:
        print(f"Warning: Could not parse location '{location_str}'. Using (0,0). Error: {e}")
        return 0.0, 0.0

def match_orders_to_vehicles(vehicles, orders, cost_model):
    print("\n--- ðŸ§  Running Dynamic Fleet Manager ---")

    available_vehicles = vehicles[vehicles['Status'] == 'available'].copy()
    if available_vehicles.empty:
        print("No vehicles are available.")
        return []

    print(f"{len(available_vehicles)} vehicles are available. {len(orders)} new orders.")


    cost_matrix = np.zeros((len(available_vehicles), len(orders)))

    vehicle_list = available_vehicles.to_dict('records')
    order_list = orders.to_dict('records')

    for i, vehicle in enumerate(vehicle_list):
        for j, order in enumerate(order_list):


            if vehicle['Capacity_KG'] < order['Capacity_KG']:
                cost_matrix[i, j] = np.inf
                continue

            order_features = pd.DataFrame([{
                'Distance_KM': order['Distance_KM'],
                'Weather_Impact': order['Weather_Impact']
            }])
            predicted_route_fuel = cost_model.predict(order_features)[0]


            vehicle_x, vehicle_y = parse_location(vehicle['Current_Location'])
            order_x, order_y = parse_location(order['Start_Location'])

            pickup_dist = np.sqrt((vehicle_x - order_x)**2 + (vehicle_y - order_y)**2)


            pickup_fuel = pickup_dist / vehicle['Fuel_Efficiency_KM_per_L']
            total_fuel = pickup_fuel + predicted_route_fuel
            total_fuel_cost = total_fuel * FUEL_PRICE_PER_LITER

            total_distance = pickup_dist + order['Distance_KM']
            total_time_hours = total_distance / AVG_SPEED_KMH
            total_time_cost = total_time_hours * DRIVER_WAGE_PER_HOUR

            total_co2_cost = total_distance * vehicle['CO2_Emissions_Kg_per_KM'] * CO2_PRICE_PER_KG

            total_cost = total_fuel_cost + total_time_cost + total_co2_cost
            cost_matrix[i, j] = total_cost


    print("Running optimization solver...")
    vehicle_indices, order_indices = linear_sum_assignment(cost_matrix)


    assignments = []
    print("\n--- âœ… Optimal Assignments Found ---")
    for v_idx, o_idx in zip(vehicle_indices, order_indices):
        vehicle = vehicle_list[v_idx]
        order = order_list[o_idx]
        cost = cost_matrix[v_idx, o_idx]

        if cost == np.inf:
            print(f"[UNMATCHED] Order {order['Order_ID']} could not be matched.")
            continue

        assignment_str = (
            f"Assign Vehicle {vehicle['Vehicle_ID']} (Type: {vehicle['Vehicle_Type']}, "
            f"Cap: {vehicle['Capacity_KG']}kg) "
            f"to Order {order['Order_ID']} (Req: {order['Capacity_KG']}kg, "
            f"Dist: {order['Distance_KM']}km) "
            f"-> Predicted Total Cost: ${cost:.2f}"
        )
        print(assignment_str)
        assignments.append((vehicle['Vehicle_ID'], order['Order_ID'], cost))


    valid_costs = cost_matrix[vehicle_indices, order_indices]
    valid_costs = valid_costs[valid_costs != np.inf]
    print(f"\nTotal cost for this dispatch: ${valid_costs.sum():.2f}")

    return assignments


if __name__ == "__main__":
    routes_path = r"/content/routes_distance.csv"
    vehicle_path = r"/content/vehicle_fleet.csv"

    vehicles_df, routes_df = load_data(vehicle_path, routes_path)

    if vehicles_df is not None and routes_df is not None:
        visualize_data(vehicles_df, routes_df)

        fuel_model = train_cost_model(routes_df)

        new_orders_df = create_new_orders()

        final_assignments = match_orders_to_vehicles(
            vehicles=vehicles_df,
            orders=new_orders_df,
            cost_model=fuel_model
        )
    else:
        print("\nExiting script due to data loading failure.")

